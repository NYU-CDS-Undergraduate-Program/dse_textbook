<!DOCTYPE html>
<html lang="en">
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-113006011-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-113006011-1');
</script>


  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Justifying Cross-Entropy Loss</title>
  <meta name="description" content="        Justifying Cross-Entropy Loss        # HIDDENimport warnings# Ignore numpy dtype warnings. These warnings are caused by an interaction# between numpy...">

  <link rel="canonical" href="https://cp71.github.io/dse_textbook/ch/17/classification_cost_justification.html">
  <link rel="alternate" type="application/rss+xml" title="Principles and Techniques of Data Science" href="https://cp71.github.io/dse_textbook/feed.xml">

  <meta property="og:url"         content="https://cp71.github.io/dse_textbook/ch/17/classification_cost_justification.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Justifying Cross-Entropy Loss" />
<meta property="og:description" content="        Justifying Cross-Entropy Loss        # HIDDENimport warnings# Ignore numpy dtype warnings. These warnings are caused by an interaction# between numpy..." />
<meta property="og:image"       content="" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "https://cp71.github.io/dse_textbook/ch/17/classification_cost_justification.html",
  "headline": "Justifying Cross-Entropy Loss",
  "datePublished": "2020-01-15T21:05:52+00:00",
  "dateModified": "2020-01-15T21:05:52+00:00",
  "description": "        Justifying Cross-Entropy Loss        # HIDDENimport warnings# Ignore numpy dtype warnings. These warnings are caused by an interaction# between numpy...",
  "author": {
    "@type": "Person",
    "name": "Sam Lau, Joey Gonzalez, and Deborah Nolan"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://cp71.github.io/dse_textbook",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://cp71.github.io/dse_textbook",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/dse_textbook/assets/css/styles.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css ">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/dse_textbook/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    }
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>

  <!-- DOM updating function -->
  <script>
const runWhenDOMLoaded = cb => {
  if (document.readyState != 'loading') {
    cb()
  } else if (document.addEventListener) {
    document.addEventListener('DOMContentLoaded', cb)
  } else {
    document.attachEvent('onreadystatechange', function() {
      if (document.readyState == 'complete') cb()
    })
  }
}

// Helper function to init things quickly
initFunction = function(myfunc) {
  runWhenDOMLoaded(myfunc);
  document.addEventListener('turbolinks:load', myfunc);
};
</script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/dse_textbook';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script>
const initAnchors = () => {
  if (window.anchors === undefined) {
    setTimeout(initAnchors, 250)
    return
  }
  anchors.add("main h1, main h2, main h3, main h4")
}

initFunction(initAnchors);
</script>


  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Selectors for elements on the page -->
  <script>
/**
 * Select various elements on the page for later use
 */

// IDs we'll attach to cells
const codeCellId = index => `codecell${index}`
const inputCellId = index => `inputcell${index}`

pageElements = {}

// All code cells
findCodeCells = function() {
    var codeCells = document.querySelectorAll('div.c-textbook__content > div.highlighter-rouge > div.highlight > pre, div.input_area pre, div.text_cell_render div.highlight pre')
    pageElements['codeCells'] = codeCells;

    codeCells.forEach((codeCell, index) => {
      const id = codeCellId(index)
      codeCell.setAttribute('id', id)
    })
};

initFunction(findCodeCells);

// All cells in general
findInputCells = function() {
    var inputCells = document.querySelectorAll('div.jb_cell')
    pageElements['inputCells'] = inputCells;

    inputCells.forEach((inputCell, index) => {
        const id = inputCellId(index)
        inputCell.setAttribute('id', id)
    })
};

initFunction(findInputCells);
</script>

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->



  <!-- Load the auto-generating TOC -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js" async></script>
<script>
const initToc = () => {
  if (window.tocbot === undefined) {
    setTimeout(initToc, 250)
    return
  }

  // Check whether we have any sidebar content. If not, then show the sidebar earlier.
  var SIDEBAR_CONTENT_TAGS = ['.tag_full_width', '.tag_popout'];
  var sidebar_content_query = SIDEBAR_CONTENT_TAGS.join(', ')
  if (document.querySelectorAll(sidebar_content_query).length === 0) {
    document.querySelector('nav.onthispage').classList.add('no_sidebar_content')
  }

  // Initialize the TOC bot
  tocbot.init({
    tocSelector: 'nav.onthispage',
    contentSelector: '.c-textbook__content',
    headingSelector: 'h2, h3',
    orderedList: false,
    collapseDepth: 6,
    listClass: 'toc__menu',
    activeListItemClass: "",  // Not using
    activeLinkClass: "", // Not using
  });

}
initFunction(initToc);
</script>


  <!-- Google analytics -->
  <script src="/dse_textbook/assets/js/ga.js" async></script>

  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/dse_textbook/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/dse_textbook/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/dse_textbook/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  

  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script>
/**
 * Set up copy/paste for code blocks
 */
const clipboardButton = id =>
  `<a id="copy-button-${id}" class="btn copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#${id}">
    <img src="/dse_textbook/assets/images/copy-button.svg" alt="Copy to clipboard">
  </a>`

// Clears selected text since ClipboardJS will select the text when copying
const clearSelection = () => {
  if (window.getSelection) {
    window.getSelection().removeAllRanges()
  } else if (document.selection) {
    document.selection.empty()
  }
}

// Changes tooltip text for two seconds, then changes it back
const temporarilyChangeTooltip = (el, newText) => {
  const oldText = el.getAttribute('data-tooltip')
  el.setAttribute('data-tooltip', newText)
  setTimeout(() => el.setAttribute('data-tooltip', oldText), 2000)
}

const addCopyButtonToCodeCells = () => {
  // If ClipboardJS hasn't loaded, wait a bit and try again. This
  // happens because we load ClipboardJS asynchronously.
  if (window.ClipboardJS === undefined) {
    setTimeout(addCopyButtonToCodeCells, 250)
    return
  }

  pageElements['codeCells'].forEach((codeCell) => {
    const id = codeCell.getAttribute('id')
    if (document.getElementById("copy-button" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', clipboardButton(id));
    }
  })

  const clipboard = new ClipboardJS('.copybtn')
  clipboard.on('success', event => {
    clearSelection()
    temporarilyChangeTooltip(event.trigger, 'Copied!')
  })

  clipboard.on('error', event => {
    temporarilyChangeTooltip(event.trigger, 'Failed to copy')
  })

  // Get rid of clipboard before the next page visit to avoid memory leak
  document.addEventListener('turbolinks:before-visit', () =>
    clipboard.destroy()
  )
}

initFunction(addCopyButtonToCodeCells);
</script>


  <!-- Hide cell code -->
  <script>
    /**
    Add buttons to hide code cells
    */


    var setCodeCellVisibility = function (inputField, kind) {
        // Update the image and class for hidden
        var id = inputField.getAttribute('data-id');
        var codeCell = document.querySelector(`#${id} div.highlight`);

        if (kind === "visible") {
            codeCell.classList.remove('hidden');
            inputField.checked = true;
        } else {
            codeCell.classList.add('hidden');
            inputField.checked = false;
        }
    }

    var toggleCodeCellVisibility = function (event) {
        // The label is clicked, and now we decide what to do based on the input field's clicked status
        if (event.target.tagName === "LABEL") {
            var inputField = event.target.previousElementSibling;
        } else {
            // It is the span inside the target
            var inputField = event.target.parentElement.previousElementSibling;
        }

        if (inputField.checked === true) {
            setCodeCellVisibility(inputField, "visible");
        } else {
            setCodeCellVisibility(inputField, "hidden");
        }
    }


    // Button constructor
    const hideCodeButton = id => `<input class="hidebtn" type="checkbox" id="hidebtn${id}" data-id="${id}"><label title="Toggle cell" for="hidebtn${id}" class="plusminus"><span class="pm_h"></span><span class="pm_v"></span></label>`

    var addHideButton = function () {
        // If a hide button is already added, don't add another
        if (document.querySelector('div.tag_hide_input input') !== null) {
            return;
        }

        // Find the input cells and add a hide button
        pageElements['inputCells'].forEach(function (inputCell) {
            if (!inputCell.classList.contains("tag_hide_input")) {
                // Skip the cell if it doesn't have a hidecode class
                return;
            }

            const id = inputCell.getAttribute('id')

            // Insert the button just inside the end of the next div
            inputCell.querySelector('div.input').insertAdjacentHTML('beforeend', hideCodeButton(id))

            // Set up the visibility toggle
            hideLink = document.querySelector(`#${id} div.inner_cell + input + label`);
            hideLink.addEventListener('click', toggleCodeCellVisibility)
        });
    }


    // Initialize the hide buttos
    var initHiddenCells = function () {
        // Add hide buttons to the cells
        addHideButton();

        // Toggle the code cells that should be hidden
        document.querySelectorAll('div.tag_hide_input input').forEach(function (item) {
            setCodeCellVisibility(item, 'hidden');
            item.checked = true;
        })
    }

    initFunction(initHiddenCells);

</script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/dse_textbook/assets/css/styles.css",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      <nav id="js-sidebar" class="c-textbook__sidebar"><h2 class="c-sidebar__title">Principles and Techniques of Data Science</h2>
  <ul class="c-sidebar__chapters"><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="http://ds100.org/"
        >Data 100 Homepage
        </a></li>
        <li class="c-sidebar__chapter">
          <a class="c-sidebar__entry"
            href="/dse_textbook/search.html"
          >
            Search This Book
          </a>
        </li>
        <li class="c-sidebar__divider"></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/intro.html"
        >Introduction
        </a></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/about_this_book.html"
        >About This Book
        </a></li><li class="c-sidebar__divider"></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/01/lifecycle_intro.html"
        >1. The Data Science Lifecycle
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/01/lifecycle_students_1.html"
                >1.1 The Students of Data 100
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/01/lifecycle_students_2.html"
                >1.2 Exploring the Data
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/01/lifecycle_students_3.html"
                >1.3 What's in a Name?
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/02/design_intro.html"
        >2. Data Design
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/02/design_dewey_truman.html"
                >2.1 Dewey Defeats Truman
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/02/design_prob_overview.html"
                >2.2 Probability Overview
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/02/design_sampling.html"
                >2.3 Probability Sampling
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/02/design_srs_vs_big_data.html"
                >2.4 SRS vs. "Big Data"
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/03/pandas_intro.html"
        >3. Tabular Data and pandas
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/03/pandas_structure.html"
                >3.1 Structure
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/03/pandas_indexes.html"
                >3.2 Indexes, Slicing, and Sorting
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/03/pandas_grouping_pivoting.html"
                >3.3 Grouping and Pivoting
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/03/pandas_apply_strings_plotting.html"
                >3.4 Apply, Strings, and Plotting
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/04/eda_intro.html"
        >4. Exploratory Data Analysis
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/04/eda_data_types.html"
                >4.1 Data Types
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href=".html"
                >4.2 Distributions [in progress]
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href=".html"
                >4.3 Associations [in progress]
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/05/cleaning_intro.html"
        >5. Data Cleaning
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/05/cleaning_calls.html"
                >5.1 Cleaning the Calls Dataset
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/05/cleaning_stops.html"
                >5.2 Cleaning the Stops Dataset
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/05/cleaning_structure.html"
                >5.3 Structure and Joins
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/05/cleaning_granularity.html"
                >5.4 Granularity
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/05/cleaning_scope.html"
                >5.5 Scope
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/05/cleaning_temp.html"
                >5.6 Temporality
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/05/cleaning_faithfulness.html"
                >5.7 Faithfulness
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/06/viz_intro.html"
        >6. Data Visualization
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/06/viz_quantitative.html"
                >6.1 Quantitative Data
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/06/viz_qualitative.html"
                >6.2 Qualitative Data
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/06/viz_matplotlib.html"
                >6.3 Customizing Plots
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/06/viz_principles.html"
                >6.4 Principles of Visualization
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/06/viz_principles_2.html"
                >6.5 Principles of Visualization 2
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/06/viz_philosophy.html"
                >6.6 Visualization Philosophy
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/07/web_intro.html"
        >7. Web Technologies
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/07/web_http.html"
                >7.1 HTTP
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/08/text_intro.html"
        >8. Working With Text
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/08/text_strings.html"
                >8.1 Python String Methods
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/08/text_regex.html"
                >8.2 Regular Expressions
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/08/text_re.html"
                >8.3 Regex in Python and pandas
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/09/sql_intro.html"
        >9. Databases and SQL
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/09/sql_rdbms.html"
                >9.1 Relational Databases
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/09/sql_basics.html"
                >9.2 SQL Queries
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/09/sql_joins.html"
                >9.3 SQL Joins
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/10/modeling_intro.html"
        >10. Modeling and Estimation
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/10/modeling_simple.html"
                >10.1 A Simple Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/10/modeling_loss_functions.html"
                >10.2 Loss Functions
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/10/modeling_abs_huber.html"
                >10.3 Absolute Cost and Huber Cost
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/11/gradient_descent.html"
        >11. Gradient Descent
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/11/gradient_basics.html"
                >11.1 Basic Numerical Optimization
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/11/gradient_descent_define.html"
                >11.2 Defining Gradient Descent
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/11/gradient_convexity.html"
                >11.3 Convexity
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/11/gradient_stochastic.html"
                >11.4 Stochastic Gradient Descent
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/12/prob_and_gen.html"
        >12. Probability and Generalization
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/12/prob_random_vars.html"
                >12.1 Random Variables
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/12/prob_exp_var.html"
                >12.2 Expectation and Variance
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/12/prob_risk.html"
                >12.3 Risk
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/13/linear_models.html"
        >13. Linear Regression
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/13/linear_tips.html"
                >13.1 Defining a Simple Linear Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/13/linear_grad.html"
                >13.2 Fitting the Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/13/linear_multiple.html"
                >13.3 Multiple Linear Regression
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/13/linear_projection.html"
                >13.4 A Geometric Perspective
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/13/linear_case_study.html"
                >13.5 Linear Regression Case Study
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/14/feature_engineering.html"
        >14. Feature Engineering
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/14/feature_one_hot.html"
                >14.1 One-Hot Encoding
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/14/feature_polynomial.html"
                >14.2 Polynomial Regression
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/15/bias_intro.html"
        >15. Bias-Variance Tradeoff
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/15/bias_risk.html"
                >15.1 Risk and Cost Minimization
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/15/bias_modeling.html"
                >15.2 Model Bias and Variance
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/15/bias_cv.html"
                >15.3 Cross Validation
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/16/reg_intro.html"
        >16. Regularization
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/16/reg_intuition.html"
                >16.1 Regularization Intuition
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/16/reg_ridge.html"
                >16.2 L2 Regularization
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/16/reg_lasso.html"
                >16.3 L1 Regularization
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/17/classification_intro.html"
        >17. Classification
        </a><ul class="c-sidebar__sections "><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/17/classification_prob.html"
                >17.1 Regression on Probabilities
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/17/classification_log_model.html"
                >17.2 Logistic Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/17/classification_cost.html"
                >17.3 Cross-Entropy Loss
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/17/classification_log_reg.html"
                >17.4 Using Logistic Regression
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry c-sidebar__entry--active"
                  href="/dse_textbook/ch/17/classification_cost_justification.html"
                >17.5 Justifying Cross-Entropy Loss
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/17/classification_sgd.html"
                >17.6 Fitting a Logistic Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/17/classification_sensitivity_specificity.html"
                >17.7 Evaluating Logistic Models
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/17/classification_multiclass.html"
                >17.8 Multiclass Classification
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/18/hyp_intro.html"
        >18. Statistical Inference
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/18/hyp_introduction.html"
                >18.1 Introduction to Hypothesis Testing
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/18/hyp_introduction_part2.html"
                >18.2 Permutation Testing
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/18/hyp_regression.html"
                >18.3 Bootstrapping for Linear Regression
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/18/hyp_studentized.html"
                >18.4 Studentized Bootstrap
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/18/hyp_phacking.html"
                >18.5 P-Hacking
                </a></li></ul></li><li class="c-sidebar__divider"></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/19/vector_space_review.html"
        >Appendix: Vector Space Review
        </a></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/20/ref_intro.html"
        >Appendix: Reference Tables
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/20/ref_pandas.html"
                >pandas
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/20/ref_seaborn.html"
                >seaborn
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/20/ref_matplotlib.html"
                >matplotlib
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/dse_textbook/ch/20/ref_sklearn.html"
                >scikit-learn
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/dse_textbook/ch/21/contributors.html"
        >Appendix: Contributors
        </a></li></ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><i class="fa fa-download"></i></button>
    <div class="download-buttons">
        <a href="/dse_textbook/content/ch/17/classification_cost_justification.ipynb" download>
        <button id="interact-button-download" class="interact-button">ORIG</button>
        </a>
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">PDF</button></a>
    </div>
</div>

  
  
  
  


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><i class="fa fa-list"></i>   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/dse_textbook/search.html" class="topbar-right-button" id="search-button"><i class="fa fa-search"></i></a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
                  <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Justifying Cross-Entropy Loss</div>
</div>
    <div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="c1"># Ignore numpy dtype warnings. These warnings are caused by an interaction</span>
<span class="c1"># between numpy and Cython and can be safely ignored.</span>
<span class="c1"># Reference: https://stackoverflow.com/a/40846742</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.dtype size changed&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.ufunc size changed&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Approximating-the-Empirical-Probability-Distribution">Approximating the Empirical Probability Distribution<a class="anchor-link" href="#Approximating-the-Empirical-Probability-Distribution"> </a></h2><p>In this section, we introduce <strong>KL divergence</strong> and demonstrate how minimizing average KL divergence in binary classification is equivalent to minimizing average cross-entropy loss.</p>
<p>Since logistic regression outputs probabilities, a logistic model produces a certain type of probability distribution. Specifically, based on optimal parameters $ \hat{\boldsymbol{\theta}} $, it estimates the probability that the label $ y $ is $ 1 $ for an example input $ \textbf{x} $.</p>
<p>For example, suppose that $ x $ is a scalar recording the forecasted chance of rain for the day and $ y = 1 $ means that Mr. Doe takes his umbrella with him to work. A logistic model with scalar parameter $ \hat{\theta} $ predicts the probability that Mr. Doe takes his umbrella given a forecasted chance of rain: $ \hat{P_\theta}(y = 1 | x) $.</p>
<p>Collecting data on Mr. Doe's umbrella usage provides us with a method of constructing an empirical probability distribution $ P(y = 1 | x) $. For example, if there were five days where the chance of rain $ x = 0.60 $ and Mr. Doe only took his umbrella to work once, $ P(y = 1 | x = 0.60) = 0.20 $. We can compute a similar probability distribution for each value of $ x $ that appears in our data. Naturally, after fitting a logistic model we would like the distribution predicted by the model to be as close as possible to the empirical distribution from the dataset. That is, for all values of $ x $ that appear in our data, we want:</p>
$$ \hat{P_\theta}(y = 1 | x) \approx P(y = 1 | x) $$<p>One commonly used metric to determine the "closeness" of two probability distributions is the Kullbackâ€“Leibler divergence, or KL divergence, which has its roots in information theory.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-Average-KL-Divergence">Defining Average KL Divergence<a class="anchor-link" href="#Defining-Average-KL-Divergence"> </a></h2><p>KL divergence quantifies the difference between the probability distribution $\hat{P_\boldsymbol{\theta}}$ computed by our logistic model with parameters $ \boldsymbol{\theta} $ and the actual distribution $ P $ based on the dataset. Intuitively, it calculates how imprecisely the logistic model estimates the distribution of labels in data.</p>
<p>The KL divergence for binary classification between two distributions $P$ and $\hat{P_\boldsymbol{\theta}}$ for a single data point $(\textbf{x}, y)$ is given by:</p>
$$D(P || \hat{P_\boldsymbol{\theta}}) = P(y = 0 | \textbf{x}) \ln \left(\frac{P(y = 0 | \textbf{x})}{\hat{P_\boldsymbol{\theta}}(y = 0 | \textbf{x})}\right) + P(y = 1 | \textbf{x}) \ln \left(\frac{P(y = 1 | \textbf{x})}{\hat{P_\boldsymbol{\theta}}(y = 1 | \textbf{x})}\right)$$<p>KL divergence is not symmetric, i.e., the divergence of $\hat{P_\boldsymbol{\theta}}$ from $P$ is not the same as the divergence of $P$ from $\hat{P_\boldsymbol{\theta}}$: $$D(P || \hat{P_\boldsymbol{\theta}}) \neq D(\hat{P_\boldsymbol{\theta}} || P)$$</p>
<p>Since our goal is to use $\hat{P_\boldsymbol{\theta}}$ to approximate $P$, we are concerned with $ D(P || \hat{P_\boldsymbol{\theta}}) $.</p>
<p>The best $\boldsymbol{\theta}$ values, which we denote as $\hat{\boldsymbol{\theta}}$, minimize the average KL divergence of the entire dataset of $n$ points:</p>
$$ \text{Average KL Divergence} = \frac{1}{n} \sum_{i=1}^{n} \left(P(y_i = 0 | \textbf{X}_i) \ln \left(\frac{P(y_i = 0 | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = 0 | \textbf{X}_i)}\right) + P(y_i = 1 | \textbf{X}_i) \ln \left(\frac{P(y_i = 1 | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = 1 | \textbf{X}_i)}\right)\right)$$$$ \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\boldsymbol{\theta}}} (\text{Average KL Divergence}) $$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the above equation, the $i^{\text{th}}$ data point is represented as ($ \textbf{X}_i $, $ y_i $) where $ \textbf{X}_i $ is the $i^{\text{th}}$ row of the $n \times p$ data matrix $\textbf{X}$ and $ y_i $ is the observed outcome.</p>
<p>KL divergence does not penalize mismatch for rare events with respect to $P$. If the model predicts a high probability for an event that is actually rare, then both $P(k)$ and $\ln \left(\frac{P(k)}{\hat{P_\boldsymbol{\theta}}(k)}\right)$ are low so the divergence is also low. However, if the model predicts a low probability for an event that is actually common, then the divergence is high. We can deduce that a logistic model that accurately predicts common events has a lower divergence from $P$ than does a model that accurately predicts rare events but varies widely on common events.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Deriving-Cross-Entropy-Loss-from-KL-Divergence">Deriving Cross-Entropy Loss from KL Divergence<a class="anchor-link" href="#Deriving-Cross-Entropy-Loss-from-KL-Divergence"> </a></h2><p>The structure of the above average KL divergence equation contains some surface similarities with cross-entropy loss. We will now show with some algebraic manipulation that minimizing average KL divergence is in fact equivalent to minimizing average cross-entropy loss.</p>
<p>Using properties of logarithms, we can rewrite the weighted log ratio:
$$P(y_i = k | \textbf{X}_i) \ln \left(\frac{P(y_i = k | \textbf{X}_i)}{\hat{P_\boldsymbol{\theta}}(y_i = k | \textbf{X}_i)}\right) = P(y_i = k | \textbf{X}_i) \ln P(y_i = k | \textbf{X}_i) - P(y_i = k | \textbf{X}_i) \ln \hat{P_\boldsymbol{\theta}}(y_i = k | \textbf{X}_i)$$</p>
<p>Note that since the first term doesn't depend on $\boldsymbol{\theta}$, it doesn't affect $\displaystyle\arg \min_{\substack{\boldsymbol{\theta}}}$ and can be removed from the equation. The resulting expression is the cross-entropy loss of the model $\hat{P_\boldsymbol{\theta}}$:</p>
$$ \text{Average Cross-Entropy Loss} = \frac{1}{n} \sum_{i=1}^{n} - P(y_i = 0 | \textbf{X}_i) \ln \hat{P_\theta}(y_i = 0 | \textbf{X}_i) - P(y_i = 1 | \textbf{X}_i) \ln \hat{P_\theta}(y_i = 1 | \textbf{X}_i)$$$$ \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\theta}} (\text{Average Cross-Entropy Loss}) $$<p>Since the label $y_i$ is a known value, the probability that $y_i = 1$, $P(y_i = 1 | \textbf{X}_i)$, is equal to $y_i$ and $P(y_i = 0 | \textbf{X}_i)$ is equal to $1 - y_i$. The model's probability distribution $\hat{P_\boldsymbol{\theta}}$ is given by the output of the sigmoid function discussed in the previous two sections. After making these substitutions, we arrive at the average cross-entropy loss equation:</p>
$$ \text{Average Cross-Entropy Loss} = \frac{1}{n} \sum_i \left(- y_i \ln (f_\hat{\boldsymbol{\theta}}(\textbf{X}_i)) - (1 - y_i) \ln (1 - f_\hat{\boldsymbol{\theta}}(\textbf{X}_i) \right) $$$$ \hat{\boldsymbol{\theta}} = \displaystyle\arg \min_{\substack{\theta}} (\text{Average Cross-Entropy Loss}) $$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Statistical-justification-for-Cross-Entropy-Loss">Statistical justification for Cross-Entropy Loss<a class="anchor-link" href="#Statistical-justification-for-Cross-Entropy-Loss"> </a></h2><p>The cross-entropy loss also has fundamental underpinnings in statistics. Since the logistic regression model predicts probabilities, given a particular logistic model we can ask, "What is the probability that this model produced the set of observed outcomes $ \textbf{y} $?" We might naturally adjust the parameters of our model until the probability of drawing our dataset from the model is as high as possible. Although we will not prove it in this section, this procedure is equivalent to minimizing the cross-entropy lossâ€”this is the <em>maximum likelihood</em> statistical justification for the cross-entropy loss.</p>
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary"> </a></h2><p>Average KL divergence can be interpreted as the average log difference between the two distributions $P$ and $\hat{P_\boldsymbol{\theta}}$ weighted by $P$. Minimizing average KL divergence also minimizes average cross-entropy loss. We can reduce the divergence of logistic regression models by selecting parameters that accurately classify commonly occurring data.</p>

</div>
</div>
</div>
</div>

 


    </main>
    
            </div>
            <nav class="c-page__nav">
  
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/dse_textbook/ch/17/classification_log_reg.html">
      ã€ˆ <span class="u-margin-right-tiny"></span> 
    </a>
  

  
    <a id="js-page__nav__next" class="c-page__nav__next" href="/dse_textbook/ch/17/classification_sgd.html">
       <span class="u-margin-right-tiny"></span> ã€‰
    </a>
  
</nav>

            <footer>
  <p class="footer"></p>
</footer>

        </div>
      </main>
    </div>
  </body>
</html>
