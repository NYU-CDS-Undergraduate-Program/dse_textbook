<!DOCTYPE html>
<html lang="en">
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-113006011-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-113006011-1');
</script>


  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Loss Functions</title>
  <meta name="description" content="        Loss Functions        # HIDDENimport warnings# Ignore numpy dtype warnings. These warnings are caused by an interaction# between numpy and Cython and...">

  <link rel="canonical" href="https://cp71.github.io/textbook/ch/10/modeling_loss_functions.html">
  <link rel="alternate" type="application/rss+xml" title="Principles and Techniques of Data Science" href="https://cp71.github.io/textbook/feed.xml">

  <meta property="og:url"         content="https://cp71.github.io/textbook/ch/10/modeling_loss_functions.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Loss Functions" />
<meta property="og:description" content="        Loss Functions        # HIDDENimport warnings# Ignore numpy dtype warnings. These warnings are caused by an interaction# between numpy and Cython and..." />
<meta property="og:image"       content="" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "https://cp71.github.io/textbook/ch/10/modeling_loss_functions.html",
  "headline": "Loss Functions",
  "datePublished": "2020-01-15T20:58:13+00:00",
  "dateModified": "2020-01-15T20:58:13+00:00",
  "description": "        Loss Functions        # HIDDENimport warnings# Ignore numpy dtype warnings. These warnings are caused by an interaction# between numpy and Cython and...",
  "author": {
    "@type": "Person",
    "name": "Sam Lau, Joey Gonzalez, and Deborah Nolan"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://cp71.github.io/textbook",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://cp71.github.io/textbook",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/textbook/assets/css/styles.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css ">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/textbook/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    }
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>

  <!-- DOM updating function -->
  <script>
const runWhenDOMLoaded = cb => {
  if (document.readyState != 'loading') {
    cb()
  } else if (document.addEventListener) {
    document.addEventListener('DOMContentLoaded', cb)
  } else {
    document.attachEvent('onreadystatechange', function() {
      if (document.readyState == 'complete') cb()
    })
  }
}

// Helper function to init things quickly
initFunction = function(myfunc) {
  runWhenDOMLoaded(myfunc);
  document.addEventListener('turbolinks:load', myfunc);
};
</script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/textbook';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script>
const initAnchors = () => {
  if (window.anchors === undefined) {
    setTimeout(initAnchors, 250)
    return
  }
  anchors.add("main h1, main h2, main h3, main h4")
}

initFunction(initAnchors);
</script>


  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Selectors for elements on the page -->
  <script>
/**
 * Select various elements on the page for later use
 */

// IDs we'll attach to cells
const codeCellId = index => `codecell${index}`
const inputCellId = index => `inputcell${index}`

pageElements = {}

// All code cells
findCodeCells = function() {
    var codeCells = document.querySelectorAll('div.c-textbook__content > div.highlighter-rouge > div.highlight > pre, div.input_area pre, div.text_cell_render div.highlight pre')
    pageElements['codeCells'] = codeCells;

    codeCells.forEach((codeCell, index) => {
      const id = codeCellId(index)
      codeCell.setAttribute('id', id)
    })
};

initFunction(findCodeCells);

// All cells in general
findInputCells = function() {
    var inputCells = document.querySelectorAll('div.jb_cell')
    pageElements['inputCells'] = inputCells;

    inputCells.forEach((inputCell, index) => {
        const id = inputCellId(index)
        inputCell.setAttribute('id', id)
    })
};

initFunction(findInputCells);
</script>

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->



  <!-- Load the auto-generating TOC -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js" async></script>
<script>
const initToc = () => {
  if (window.tocbot === undefined) {
    setTimeout(initToc, 250)
    return
  }

  // Check whether we have any sidebar content. If not, then show the sidebar earlier.
  var SIDEBAR_CONTENT_TAGS = ['.tag_full_width', '.tag_popout'];
  var sidebar_content_query = SIDEBAR_CONTENT_TAGS.join(', ')
  if (document.querySelectorAll(sidebar_content_query).length === 0) {
    document.querySelector('nav.onthispage').classList.add('no_sidebar_content')
  }

  // Initialize the TOC bot
  tocbot.init({
    tocSelector: 'nav.onthispage',
    contentSelector: '.c-textbook__content',
    headingSelector: 'h2, h3',
    orderedList: false,
    collapseDepth: 6,
    listClass: 'toc__menu',
    activeListItemClass: "",  // Not using
    activeLinkClass: "", // Not using
  });

}
initFunction(initToc);
</script>


  <!-- Google analytics -->
  <script src="/textbook/assets/js/ga.js" async></script>

  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/textbook/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/textbook/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/textbook/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  

  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script>
/**
 * Set up copy/paste for code blocks
 */
const clipboardButton = id =>
  `<a id="copy-button-${id}" class="btn copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#${id}">
    <img src="/textbook/assets/images/copy-button.svg" alt="Copy to clipboard">
  </a>`

// Clears selected text since ClipboardJS will select the text when copying
const clearSelection = () => {
  if (window.getSelection) {
    window.getSelection().removeAllRanges()
  } else if (document.selection) {
    document.selection.empty()
  }
}

// Changes tooltip text for two seconds, then changes it back
const temporarilyChangeTooltip = (el, newText) => {
  const oldText = el.getAttribute('data-tooltip')
  el.setAttribute('data-tooltip', newText)
  setTimeout(() => el.setAttribute('data-tooltip', oldText), 2000)
}

const addCopyButtonToCodeCells = () => {
  // If ClipboardJS hasn't loaded, wait a bit and try again. This
  // happens because we load ClipboardJS asynchronously.
  if (window.ClipboardJS === undefined) {
    setTimeout(addCopyButtonToCodeCells, 250)
    return
  }

  pageElements['codeCells'].forEach((codeCell) => {
    const id = codeCell.getAttribute('id')
    if (document.getElementById("copy-button" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', clipboardButton(id));
    }
  })

  const clipboard = new ClipboardJS('.copybtn')
  clipboard.on('success', event => {
    clearSelection()
    temporarilyChangeTooltip(event.trigger, 'Copied!')
  })

  clipboard.on('error', event => {
    temporarilyChangeTooltip(event.trigger, 'Failed to copy')
  })

  // Get rid of clipboard before the next page visit to avoid memory leak
  document.addEventListener('turbolinks:before-visit', () =>
    clipboard.destroy()
  )
}

initFunction(addCopyButtonToCodeCells);
</script>


  <!-- Hide cell code -->
  <script>
    /**
    Add buttons to hide code cells
    */


    var setCodeCellVisibility = function (inputField, kind) {
        // Update the image and class for hidden
        var id = inputField.getAttribute('data-id');
        var codeCell = document.querySelector(`#${id} div.highlight`);

        if (kind === "visible") {
            codeCell.classList.remove('hidden');
            inputField.checked = true;
        } else {
            codeCell.classList.add('hidden');
            inputField.checked = false;
        }
    }

    var toggleCodeCellVisibility = function (event) {
        // The label is clicked, and now we decide what to do based on the input field's clicked status
        if (event.target.tagName === "LABEL") {
            var inputField = event.target.previousElementSibling;
        } else {
            // It is the span inside the target
            var inputField = event.target.parentElement.previousElementSibling;
        }

        if (inputField.checked === true) {
            setCodeCellVisibility(inputField, "visible");
        } else {
            setCodeCellVisibility(inputField, "hidden");
        }
    }


    // Button constructor
    const hideCodeButton = id => `<input class="hidebtn" type="checkbox" id="hidebtn${id}" data-id="${id}"><label title="Toggle cell" for="hidebtn${id}" class="plusminus"><span class="pm_h"></span><span class="pm_v"></span></label>`

    var addHideButton = function () {
        // If a hide button is already added, don't add another
        if (document.querySelector('div.tag_hide_input input') !== null) {
            return;
        }

        // Find the input cells and add a hide button
        pageElements['inputCells'].forEach(function (inputCell) {
            if (!inputCell.classList.contains("tag_hide_input")) {
                // Skip the cell if it doesn't have a hidecode class
                return;
            }

            const id = inputCell.getAttribute('id')

            // Insert the button just inside the end of the next div
            inputCell.querySelector('div.input').insertAdjacentHTML('beforeend', hideCodeButton(id))

            // Set up the visibility toggle
            hideLink = document.querySelector(`#${id} div.inner_cell + input + label`);
            hideLink.addEventListener('click', toggleCodeCellVisibility)
        });
    }


    // Initialize the hide buttos
    var initHiddenCells = function () {
        // Add hide buttons to the cells
        addHideButton();

        // Toggle the code cells that should be hidden
        document.querySelectorAll('div.tag_hide_input input').forEach(function (item) {
            setCodeCellVisibility(item, 'hidden');
            item.checked = true;
        })
    }

    initFunction(initHiddenCells);

</script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/textbook/assets/css/styles.css",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      <nav id="js-sidebar" class="c-textbook__sidebar"><h2 class="c-sidebar__title">Principles and Techniques of Data Science</h2>
  <ul class="c-sidebar__chapters"><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="http://ds100.org/"
        >Data 100 Homepage
        </a></li>
        <li class="c-sidebar__chapter">
          <a class="c-sidebar__entry"
            href="/textbook/search.html"
          >
            Search This Book
          </a>
        </li>
        <li class="c-sidebar__divider"></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/intro.html"
        >Introduction
        </a></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/about_this_book.html"
        >About This Book
        </a></li><li class="c-sidebar__divider"></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/01/lifecycle_intro.html"
        >1. The Data Science Lifecycle
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/01/lifecycle_students_1.html"
                >1.1 The Students of Data 100
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/01/lifecycle_students_2.html"
                >1.2 Exploring the Data
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/01/lifecycle_students_3.html"
                >1.3 What's in a Name?
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/02/design_intro.html"
        >2. Data Design
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/02/design_dewey_truman.html"
                >2.1 Dewey Defeats Truman
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/02/design_prob_overview.html"
                >2.2 Probability Overview
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/02/design_sampling.html"
                >2.3 Probability Sampling
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/02/design_srs_vs_big_data.html"
                >2.4 SRS vs. "Big Data"
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/03/pandas_intro.html"
        >3. Tabular Data and pandas
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/03/pandas_structure.html"
                >3.1 Structure
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/03/pandas_indexes.html"
                >3.2 Indexes, Slicing, and Sorting
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/03/pandas_grouping_pivoting.html"
                >3.3 Grouping and Pivoting
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/03/pandas_apply_strings_plotting.html"
                >3.4 Apply, Strings, and Plotting
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/04/eda_intro.html"
        >4. Exploratory Data Analysis
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/04/eda_data_types.html"
                >4.1 Data Types
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href=".html"
                >4.2 Distributions [in progress]
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href=".html"
                >4.3 Associations [in progress]
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/05/cleaning_intro.html"
        >5. Data Cleaning
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/05/cleaning_calls.html"
                >5.1 Cleaning the Calls Dataset
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/05/cleaning_stops.html"
                >5.2 Cleaning the Stops Dataset
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/05/cleaning_structure.html"
                >5.3 Structure and Joins
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/05/cleaning_granularity.html"
                >5.4 Granularity
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/05/cleaning_scope.html"
                >5.5 Scope
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/05/cleaning_temp.html"
                >5.6 Temporality
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/05/cleaning_faithfulness.html"
                >5.7 Faithfulness
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/06/viz_intro.html"
        >6. Data Visualization
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/06/viz_quantitative.html"
                >6.1 Quantitative Data
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/06/viz_qualitative.html"
                >6.2 Qualitative Data
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/06/viz_matplotlib.html"
                >6.3 Customizing Plots
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/06/viz_principles.html"
                >6.4 Principles of Visualization
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/06/viz_principles_2.html"
                >6.5 Principles of Visualization 2
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/06/viz_philosophy.html"
                >6.6 Visualization Philosophy
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/07/web_intro.html"
        >7. Web Technologies
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/07/web_http.html"
                >7.1 HTTP
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/08/text_intro.html"
        >8. Working With Text
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/08/text_strings.html"
                >8.1 Python String Methods
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/08/text_regex.html"
                >8.2 Regular Expressions
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/08/text_re.html"
                >8.3 Regex in Python and pandas
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/09/sql_intro.html"
        >9. Databases and SQL
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/09/sql_rdbms.html"
                >9.1 Relational Databases
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/09/sql_basics.html"
                >9.2 SQL Queries
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/09/sql_joins.html"
                >9.3 SQL Joins
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/10/modeling_intro.html"
        >10. Modeling and Estimation
        </a><ul class="c-sidebar__sections "><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/10/modeling_simple.html"
                >10.1 A Simple Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry c-sidebar__entry--active"
                  href="/textbook/ch/10/modeling_loss_functions.html"
                >10.2 Loss Functions
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/10/modeling_abs_huber.html"
                >10.3 Absolute Cost and Huber Cost
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/11/gradient_descent.html"
        >11. Gradient Descent
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/11/gradient_basics.html"
                >11.1 Basic Numerical Optimization
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/11/gradient_descent_define.html"
                >11.2 Defining Gradient Descent
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/11/gradient_convexity.html"
                >11.3 Convexity
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/11/gradient_stochastic.html"
                >11.4 Stochastic Gradient Descent
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/12/prob_and_gen.html"
        >12. Probability and Generalization
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/12/prob_random_vars.html"
                >12.1 Random Variables
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/12/prob_exp_var.html"
                >12.2 Expectation and Variance
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/12/prob_risk.html"
                >12.3 Risk
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/13/linear_models.html"
        >13. Linear Regression
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/13/linear_tips.html"
                >13.1 Defining a Simple Linear Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/13/linear_grad.html"
                >13.2 Fitting the Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/13/linear_multiple.html"
                >13.3 Multiple Linear Regression
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/13/linear_projection.html"
                >13.4 A Geometric Perspective
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/13/linear_case_study.html"
                >13.5 Linear Regression Case Study
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/14/feature_engineering.html"
        >14. Feature Engineering
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/14/feature_one_hot.html"
                >14.1 One-Hot Encoding
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/14/feature_polynomial.html"
                >14.2 Polynomial Regression
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/15/bias_intro.html"
        >15. Bias-Variance Tradeoff
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/15/bias_risk.html"
                >15.1 Risk and Cost Minimization
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/15/bias_modeling.html"
                >15.2 Model Bias and Variance
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/15/bias_cv.html"
                >15.3 Cross Validation
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/16/reg_intro.html"
        >16. Regularization
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/16/reg_intuition.html"
                >16.1 Regularization Intuition
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/16/reg_ridge.html"
                >16.2 L2 Regularization
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/16/reg_lasso.html"
                >16.3 L1 Regularization
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/17/classification_intro.html"
        >17. Classification
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/17/classification_prob.html"
                >17.1 Regression on Probabilities
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/17/classification_log_model.html"
                >17.2 Logistic Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/17/classification_cost.html"
                >17.3 Cross-Entropy Loss
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/17/classification_log_reg.html"
                >17.4 Using Logistic Regression
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/17/classification_cost_justification.html"
                >17.5 Justifying Cross-Entropy Loss
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/17/classification_sgd.html"
                >17.6 Fitting a Logistic Model
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/17/classification_sensitivity_specificity.html"
                >17.7 Evaluating Logistic Models
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/17/classification_multiclass.html"
                >17.8 Multiclass Classification
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/18/hyp_intro.html"
        >18. Statistical Inference
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/18/hyp_introduction.html"
                >18.1 Introduction to Hypothesis Testing
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/18/hyp_introduction_part2.html"
                >18.2 Permutation Testing
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/18/hyp_regression.html"
                >18.3 Bootstrapping for Linear Regression
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/18/hyp_studentized.html"
                >18.4 Studentized Bootstrap
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/18/hyp_phacking.html"
                >18.5 P-Hacking
                </a></li></ul></li><li class="c-sidebar__divider"></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/19/vector_space_review.html"
        >Appendix: Vector Space Review
        </a></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/20/ref_intro.html"
        >Appendix: Reference Tables
        </a><ul class="c-sidebar__sections u-hidden-visually"><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/20/ref_pandas.html"
                >pandas
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/20/ref_seaborn.html"
                >seaborn
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/20/ref_matplotlib.html"
                >matplotlib
                </a></li><li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/textbook/ch/20/ref_sklearn.html"
                >scikit-learn
                </a></li></ul></li><li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/textbook/ch/21/contributors.html"
        >Appendix: Contributors
        </a></li></ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><i class="fa fa-download"></i></button>
    <div class="download-buttons">
        <a href="/textbook/content/ch/10/modeling_loss_functions.ipynb" download>
        <button id="interact-button-download" class="interact-button">ORIG</button>
        </a>
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">PDF</button></a>
    </div>
</div>

  
  
  
  


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><i class="fa fa-list"></i>   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/textbook/search.html" class="topbar-right-button" id="search-button"><i class="fa fa-search"></i></a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
                  <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Loss Functions</div>
</div>
    <div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="c1"># Ignore numpy dtype warnings. These warnings are caused by an interaction</span>
<span class="c1"># between numpy and Cython and can be safely ignored.</span>
<span class="c1"># Reference: https://stackoverflow.com/a/40846742</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.dtype size changed&quot;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;numpy.ufunc size changed&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">nbinteract</span> <span class="k">as</span> <span class="nn">nbi</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># This option stops scientific notation for pandas</span>
<span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.2f}&#39;.format)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">tips</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;tips&#39;</span><span class="p">)</span>
<span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tips</span><span class="p">[</span><span class="s1">&#39;tip&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">tips</span><span class="p">[</span><span class="s1">&#39;total_bill&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-Functions">Loss Functions<a class="anchor-link" href="#Loss-Functions"> </a></h2><p>Recall our assumptions thus far: we assume that there is a single population tip percentage $ \theta^* $. Our model estimates this parameter; we use the variable $ \theta $ to denote our estimate. We would like to use the collected data on tips to determine the value that $ \theta $ should have,</p>
<p>To precisely decide which value of $ \theta $ is best, we define a <strong>loss function</strong>. A loss function is a mathematical function that takes in an estimate $ \theta $ and the points in our dataset $y_1, y_2, \ldots, y_n$. It outputs a single number, the <strong>loss</strong>, that measures how well $ \theta $ fits our data. In mathematical notation, we want to create the function:</p>
$$ L(\theta, y_1, y_2, \ldots, y_n) =\ \ldots $$<p>By convention, the loss function outputs lower values for preferable values of $ \theta $ and larger values for worse values of $ \theta $. To fit our model, we select the value of $ \theta $ that produces a lower loss than all other choices of $ \theta $—the $ \theta $ that <strong>minimizes the loss</strong>. We use the notation $ \hat{\theta} $ to denote the value of $ \theta $ that minimizes a specified loss function.</p>
<p>Consider once again two possible values of $ \theta $: $ \theta = 10 $ and $ \theta = 15 $.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">rug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$ \theta = 10$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;darkgreen&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$ \theta = 15$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Percent Tip Amount&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion per Percent&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_3_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since $ \theta = 15 $ falls closer to most of the points, our loss function should output a small value for $ \theta = 15 $ and a larger value for $ \theta = 10 $.</p>
<p>Let's use this intuition to create a loss function.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Our-First-Loss-Function:-Mean-Squared-Error">Our First Loss Function: Mean Squared Error<a class="anchor-link" href="#Our-First-Loss-Function:-Mean-Squared-Error"> </a></h3><p>We would like our choice of $ \theta $ to fall close to the points in our dataset. Thus, we can define a loss function that outputs a larger value as $ \theta $ gets further away from the points in the dataset. We start with a simple loss function called the <em>mean squared error</em>. Here's the idea:</p>
<ol>
<li>We select a value of $ \theta $.</li>
<li>For each value in our dataset, take the squared difference between the value and theta: $ (y_i - \theta)^2 $ . Squaring the difference in a simple way to convert negative differences into positive ones. We want to do this because if our point $ y_i = 14 $, $ \theta = 10 $ and $ \theta = 18 $ are equally far away from the point and are thus equally "bad".</li>
<li>To compute the final loss, take the average of each of the individual squared differences.</li>
</ol>
<p>This gives us a final loss function of:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\begin{aligned}
L(\theta, y_1, y_2, \ldots, y_n)
&amp;= \text{average}\left\{ (y_1 - \theta)^2, (y_2 - \theta)^2, \ldots, (y_n - \theta)^2 \right\} \\
&amp;= \frac{1}{n} \left((y_1 - \theta)^2 + (y_2 - \theta)^2 + \ldots + (y_n - \theta)^2 \right) \\
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
$$<p>Creating a Python function to compute the loss is simple:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_vals</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see how this loss function behaves. Suppose we have a dataset only containing one point, $ y_1 = 14 $. We can try different values of $ \theta $ and see what the loss function outputs for each value.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="k">def</span> <span class="nf">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">xlims</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">mse_loss</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">cols</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_vals</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">thetas</span><span class="p">)</span> <span class="o">/</span> <span class="n">cols</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">theta</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">thetas</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">rugplot</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">rf</span><span class="s1">&#39;$ \theta = </span><span class="si">{theta}</span><span class="s1"> $&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loss = {loss_fn(theta, y_vals):.2f}&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlims</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
           <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_9_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can also interactively try different values of $ \theta $ below. You should understand why the loss for $ \theta = 11 $ is many times higher than the loss for $ \theta = 13 $.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="k">def</span> <span class="nf">try_thetas_interact</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">xlims</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">mse_loss</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_vals</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">rugplot</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlims</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loss for theta = </span><span class="si">{theta}</span><span class="s1">: {loss_fn(theta, y_vals):.2f}&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">mse_interact</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">xlims</span><span class="p">):</span>
    <span class="n">plot</span> <span class="o">=</span> <span class="n">interactive</span><span class="p">(</span><span class="n">try_thetas_interact</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span>
                       <span class="n">y_vals</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="n">y_vals</span><span class="p">),</span> <span class="n">xlims</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="n">xlims</span><span class="p">),</span>
                       <span class="n">loss_fn</span><span class="o">=</span><span class="n">fixed</span><span class="p">(</span><span class="n">mse_loss</span><span class="p">))</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">layout</span><span class="o">.</span><span class="n">height</span> <span class="o">=</span> <span class="s1">&#39;240px&#39;</span>
    <span class="k">return</span> <span class="n">plot</span>
    
<span class="n">mse_interact</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="c6f31b18-34d5-466e-9465-27feedabe3d7"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#c6f31b18-34d5-466e-9465-27feedabe3d7');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "64e436ca9d824596b27a436b723ec66b", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we hoped, our loss is larger as $ \theta $ is further away from our data and is smallest when $ \theta $ falls exactly onto our data point. Let's now see how our mean squared error behaves when we have five points instead of one. Our data this time are: $ [11, 12, 15, 17, 18 ] $.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">],</span>
           <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span>
           <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mf">10.5</span><span class="p">,</span> <span class="mf">18.5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_13_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Of the values of $ \theta $ we tried $ \theta = 15 $ has the lowest loss. However, a value of $ \theta $ in between 14 and 15 might have an even lower loss than $ \theta = 15 $. See if you can find a better value of $ \theta $ using the interactive plot below.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">mse_interact</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
             <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span>
             <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mf">10.5</span><span class="p">,</span> <span class="mf">18.5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="72e5baf9-6c9a-4fc7-9647-e3d7251a99cd"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#72e5baf9-6c9a-4fc7-9647-e3d7251a99cd');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "6f3366d970834671a0be9f459e890bee", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The mean squared error seems to be doing its job by penalizing values of $ \theta $ that are far away from the center of the data. Let's now see what the loss function outputs on the original dataset of tip percents. For reference, the original distribution of tip percents is plotted below:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">rug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Percent Tip Amount&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion per Percent&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_17_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's try some values of $ \theta $.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">14.5</span><span class="p">,</span> <span class="mf">17.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
           <span class="n">y_vals</span><span class="o">=</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span>
           <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_19_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As before, we've created an interactive widget to test different values of $ \theta $.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">mse_interact</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span>
             <span class="n">y_vals</span><span class="o">=</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span>
             <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="8a455088-875d-4d23-90ef-d1e937249be6"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#8a455088-875d-4d23-90ef-d1e937249be6');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "95aa11611b914cb6b34e72022293f0ac", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It looks like the best value of $ \theta $ that we've tried so far is 16.00, slightly above our original guess of 15% tip.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="A-Shorthand">A Shorthand<a class="anchor-link" href="#A-Shorthand"> </a></h3><p>We have defined our first loss function, the mean squared error (MSE). It computes high loss for values of $ \theta $ that are further away from the center of the data. Mathematically, this loss function is defined as:</p>
$$
\begin{aligned}
L(\theta, y_1, y_2, \ldots, y_n)
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
$$<p>The loss function will compute different losses whenever we change either $ \theta $ or $ y_1, y_2, \ldots, y_n $. We've seen this happen when we tried different values of $ \theta $ and when we added new data points (changing $ y_1, y_2, \ldots, y_n $).</p>
<p>As a shorthand, we can define the vector $ \textbf{y} = [ y_1, y_2, \ldots, y_n ] $. Then, we can write MSE as:</p>
$$
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Minimizing-the-Loss">Minimizing the Loss<a class="anchor-link" href="#Minimizing-the-Loss"> </a></h3><p>So far, we have found the best value of $ \theta $ by simply trying out a bunch of values and then picking the one with the least loss. Although this method works decently well, we can find a better method by using the properties of our loss function.</p>
<p>For the following example, we use a dataset containing five points: $ \textbf{y} = [ 11, 12, 15, 16, 17 ] $.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">try_thetas</span><span class="p">(</span><span class="n">thetas</span><span class="o">=</span><span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">],</span>
           <span class="n">y_vals</span><span class="o">=</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">],</span>
           <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mf">10.5</span><span class="p">,</span> <span class="mf">18.5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_25_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the plots above, we've used integer $ \theta $ values in between 12 and 17. When we change $ \theta $, the loss seems to start high (at 10.92), decrease until $ \theta = 15 $, then increase again. We can see that the loss changes as $ \theta $ changes, so let's make a plot comparing the loss to $ \theta $ for each of the six $ \theta $s we've tried.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">])</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">])</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Loss vs. $ \theta $ when $\bf</span><span class="si">{y}</span><span class="s1">$$ = [11, 12, 15, 17, 18] $&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $ Values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_27_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The scatter plot shows the downward, then upward trend that we noticed before. We can try more values of $ \theta $ to see a complete curve that shows how the loss changes as $ \theta $ changes.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">17.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">])</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span> <span class="k">for</span> <span class="n">theta</span> <span class="ow">in</span> <span class="n">thetas</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Loss vs. $ \theta $ when $\bf</span><span class="si">{y}</span><span class="s1">$$ = [11, 12, 15, 17, 18] $&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$ \theta $ Values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_29_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The plot above shows that in fact, $ \theta = 15$ was not the best choice; a $ \theta $ between 14 and 15 would have gotten a lower loss. We can use calculus to find that minimizing value of $ \theta $ exactly. At the minimum loss, the derivative of the loss function with respect to $ \theta $ is 0.</p>
<p>First, we start with our loss function:</p>
$$
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\end{aligned}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we plug in our points $ \textbf{y} = [11, 12, 15, 17, 18] $:</p>
$$
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{5} \big((11 - \theta)^2 + (12 - \theta)^2 + (15 - \theta)^2 + (17 - \theta)^2 + (18 - \theta)^2 \big)\\
\end{aligned}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To find the value of $ \theta $ that minimizes this function, we compute the derivative with respect to $ \theta $:</p>
$$
\begin{aligned}
\frac{\partial}{\partial \theta} L(\theta, \textbf{y})
&amp;= \frac{1}{5} \big(-2(11 - \theta) - 2(12 - \theta) - 2(15 - \theta) - 2(17 - \theta) -2(18 - \theta) \big)\\
&amp;= \frac{1}{5} \big(10 \cdot \theta - 146 \big)\\
\end{aligned}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we find the value of $ \theta $ where the derivative is zero:</p>
$$
\begin{aligned}
\frac{1}{5} \big(10 \cdot \theta - 146 \big) &amp;= 0 \\
10 \cdot \theta - 146 &amp;= 0 \\
\theta &amp;= 14.6
\end{aligned}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We've found the minimizing $ \theta $, and as expected, it is between 14 and 15. We denote the $ \theta $ that minimizes the loss $ \hat{\theta} $. Thus, for the dataset $ \textbf{y} = [11, 12, 15, 17, 18] $ and the MSE loss function:</p>
$$ \hat{\theta} = 14.6 $$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we happen to compute the mean of the data values, we notice a curious equivalence:</p>
$$ \text{mean} (\textbf{y}) = \hat{\theta} = 14.6 $$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Minimizing-Value-of-the-Mean-Squared-Error">The Minimizing Value of the Mean Squared Error<a class="anchor-link" href="#The-Minimizing-Value-of-the-Mean-Squared-Error"> </a></h3><p>As it turns out, the equivalence above is no mere coincidence; the average of the data values <em>always</em> produces $ \hat{\theta} $, the $ \theta $ that minimizes the MSE loss.</p>
<p>To show this, we take the derivative of our loss function once more. Instead of plugging in points, we leave the $ y_i $ terms intact to generalize to other datasets.</p>
$$
\begin{aligned}
L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n}(y_i - \theta)^2\\
\frac{\partial}{\partial \theta} L(\theta, \textbf{y})
&amp;= \frac{1}{n} \sum_{i = 1}^{n} -2(y_i - \theta) \\
&amp;= -\frac{2}{n} \sum_{i = 1}^{n} (y_i - \theta) \\
\end{aligned}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we did not substitute in specific values for $ y_i $, this equation can be used with any dataset with any number of points.</p>
<p>Now, we set the derivative equal to zero and solve for $ \theta $ to find the minimizing value of $ \theta $ as before:</p>
$$
\begin{aligned}
-\frac{2}{n} \sum_{i = 1}^{n} (y_i - \theta) &amp;= 0 \\
\sum_{i = 1}^{n} (y_i - \theta) &amp;= 0 \\
\sum_{i = 1}^{n} y_i - \sum_{i = 1}^{n} \theta &amp;= 0 \\
\sum_{i = 1}^{n} \theta &amp;= \sum_{i = 1}^{n} y_i \\
n \cdot \theta &amp;= y_1 + \ldots + y_n \\
\theta &amp;= \frac{y_1 + \ldots + y_n}{n} \\
\hat \theta = \theta &amp;= \text{mean} (\textbf{y})
\end{aligned}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lo and behold, we see that there is a single value of $ \theta $ that gives the least MSE no matter what the dataset is. For the mean squared error, we know that $ \hat{\theta} $ is the mean of the dataset values.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Back-to-the-Original-Dataset">Back to the Original Dataset<a class="anchor-link" href="#Back-to-the-Original-Dataset"> </a></h3><p>We no longer have to test out different values of $ \theta $ as we did before. We can compute the mean tip percentage in one go:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>16.080258172250463</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell tag_hide_input">

<div class="cell border-box-sizing code_cell rendered tag_hide_input">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># HIDDEN</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;pcttip&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">rug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">16.08</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$ \hat \theta = 16.08$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of tip percent&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Percent Tip Amount&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion per Percent&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/ch/10/modeling_loss_functions_41_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Summary">Summary<a class="anchor-link" href="#Summary"> </a></h3><p>We have introduced a <strong>constant model</strong>, a model that outputs the same number for all entries in the dataset.</p>
<p>A <strong>loss function</strong> $ L(\theta, \textbf{y}) $ measures how well a given value of $ \theta $ fits the data. In this section, we introduce the mean squared error loss function and showed that $ \hat{\theta} = \text{mean}(\textbf{y}) $ for the constant model.</p>
<p>The steps we took in this section apply to many modeling scenarios:</p>
<ol>
<li>Select a model.</li>
<li>Select a loss function.</li>
<li>Fit the model by minimizing the loss.</li>
</ol>
<p>In this book, all of our modeling techniques expand upon one or more of these steps. We introduce new models (1), new loss functions (2), and new techniques for minimizing loss (3).</p>

</div>
</div>
</div>
</div>

 


    </main>
    
            </div>
            <nav class="c-page__nav">
  
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/textbook/ch/10/modeling_simple.html">
      〈 <span class="u-margin-right-tiny"></span> 
    </a>
  

  
    <a id="js-page__nav__next" class="c-page__nav__next" href="/textbook/ch/10/modeling_abs_huber.html">
       <span class="u-margin-right-tiny"></span> 〉
    </a>
  
</nav>

            <footer>
  <p class="footer"></p>
</footer>

        </div>
      </main>
    </div>
  </body>
</html>
